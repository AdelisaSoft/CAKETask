{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv(\"../data/task_data_training.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_number_of_active_months</th>\n",
       "      <th>revenue</th>\n",
       "      <th>value_days_to_purchase</th>\n",
       "      <th>action_create_project</th>\n",
       "      <th>value_transactions_number</th>\n",
       "      <th>ws_users_activated</th>\n",
       "      <th>action_export_report</th>\n",
       "      <th>action_create_invoice</th>\n",
       "      <th>value_regular_seats</th>\n",
       "      <th>action_project_budget</th>\n",
       "      <th>action_time_entries_via_tracker</th>\n",
       "      <th>action_screenshots</th>\n",
       "      <th>churned_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>184.925</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>395.122</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25.974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>406.068</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>25.974</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value_number_of_active_months  revenue  value_days_to_purchase  \\\n",
       "0                              0  184.925                       2   \n",
       "1                              3  395.122                      98   \n",
       "2                              1   25.974                       0   \n",
       "3                              1  406.068                      53   \n",
       "4                              2   25.974                       1   \n",
       "\n",
       "   action_create_project  value_transactions_number  ws_users_activated  \\\n",
       "0                      5                          6                   3   \n",
       "1                      3                         12                   2   \n",
       "2                      0                          2                   1   \n",
       "3                      3                         12                   3   \n",
       "4                      5                          2                   1   \n",
       "\n",
       "   action_export_report  action_create_invoice  value_regular_seats  \\\n",
       "0                     8                      0                    3   \n",
       "1                     3                      0                    3   \n",
       "2                     0                      0                    1   \n",
       "3                     0                      0                    3   \n",
       "4                     8                      6                    1   \n",
       "\n",
       "   action_project_budget  action_time_entries_via_tracker  action_screenshots  \\\n",
       "0                      0                                0                 0.0   \n",
       "1                      9                                0                 1.0   \n",
       "2                      0                                0                 1.0   \n",
       "3                      0                                0                 1.0   \n",
       "4                      0                                0                 0.0   \n",
       "\n",
       "  churned_status  \n",
       "0             No  \n",
       "1             No  \n",
       "2            Yes  \n",
       "3             No  \n",
       "4             No  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = churn_df.drop(['churned_status'], axis=1)\n",
    "y = churn_df['churned_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Model after Hyperparameter Tuning:\n",
      "Best Hyperparameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 0.7288629737609329\n",
      "Confusion Matrix:\n",
      "[[173  47]\n",
      " [ 46  77]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.79      0.79       220\n",
      "         Yes       0.62      0.63      0.62       123\n",
      "\n",
      "    accuracy                           0.73       343\n",
      "   macro avg       0.71      0.71      0.71       343\n",
      "weighted avg       0.73      0.73      0.73       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],                # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],      # Kernel type\n",
    "    'gamma': ['scale', 'auto', 0.1],  # Kernel coefficient (only for 'rbf' kernel)\n",
    "}\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object to perform hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, scoring='balanced_accuracy', cv=5)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use the best hyperparameters to create a new SVM classifier\n",
    "best_svm_classifier = SVC(random_state=42, **best_params)\n",
    "\n",
    "# Fit the new classifier to the training data\n",
    "best_svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred_svm = best_svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best SVM model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "confusion_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(\"Best SVM Model after Hyperparameter Tuning:\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Accuracy: {accuracy_svm}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_svm}\")\n",
    "print(f\"Classification Report:\\n{classification_rep_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see here, our traditional fine tuning didn't work because we still have a lot of false positives and a lot of false negatives.  So will try now with over/undersampling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over/undersampling methods\n",
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6647230320699709\n",
      "Confusion Matrix:\n",
      "[[128  92]\n",
      " [ 23 100]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.58      0.69       220\n",
      "         Yes       0.52      0.81      0.63       123\n",
      "\n",
      "    accuracy                           0.66       343\n",
      "   macro avg       0.68      0.70      0.66       343\n",
      "weighted avg       0.73      0.66      0.67       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_undersampled_train, y_undersampled_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', gamma='scale', C=1, random_state=42) \n",
    "svm_classifier.fit(X_undersampled_train, y_undersampled_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6676384839650146\n",
      "Confusion Matrix:\n",
      "[[129  91]\n",
      " [ 23 100]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.59      0.69       220\n",
      "         Yes       0.52      0.81      0.64       123\n",
      "\n",
      "    accuracy                           0.67       343\n",
      "   macro avg       0.69      0.70      0.67       343\n",
      "weighted avg       0.73      0.67      0.67       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_oversampled_train, y_oversampled_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', gamma='scale', C=1, random_state=42) \n",
    "svm_classifier.fit(X_oversampled_train, y_oversampled_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7288629737609329\n",
      "Confusion Matrix:\n",
      "[[173  47]\n",
      " [ 46  77]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.79      0.79       220\n",
      "         Yes       0.62      0.63      0.62       123\n",
      "\n",
      "    accuracy                           0.73       343\n",
      "   macro avg       0.71      0.71      0.71       343\n",
      "weighted avg       0.73      0.73      0.73       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the SMOTE sampler\n",
    "smote = SMOTE(random_state=42, sampling_strategy=\"not minority\")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_oversampled_train, y_oversampled_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "svm_classifier_smote = SVC(kernel='linear', gamma='scale', C=1, random_state=42) \n",
    "svm_classifier_smote.fit(X_oversampled_train, y_oversampled_train)\n",
    "y_pred = svm_classifier_smote.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6880466472303207\n",
      "Confusion Matrix:\n",
      "[[138  82]\n",
      " [ 25  98]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.63      0.72       220\n",
      "         Yes       0.54      0.80      0.65       123\n",
      "\n",
      "    accuracy                           0.69       343\n",
      "   macro avg       0.70      0.71      0.68       343\n",
      "weighted avg       0.74      0.69      0.69       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the SMOTE sampler\n",
    "smote = SMOTE(random_state=42, sampling_strategy=\"not majority\")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_oversampled_train, y_oversampled_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', gamma='scale', C=1, random_state=42) \n",
    "svm_classifier.fit(X_oversampled_train, y_oversampled_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have concluded is that we have either 2 cases of confusion matrix:\n",
    "\\begin{bmatrix}\n",
    "138 & 82\\\\\n",
    "25 & 98\n",
    "\\end{bmatrix}\n",
    "\n",
    "and the second one\n",
    "\n",
    "\\begin{bmatrix}\n",
    "173 & 47\\\\\n",
    "46 & 77\n",
    "\\end{bmatrix}\n",
    "\n",
    "The first one is predicting classes fairly correctly, but tells you a lot of times that someone is will be a churn customer (82 times) even though they aren't. And the worst case (false negatives), or in other words - the case where we think someone won't become churn customer and they actually will is still relatively very small. (hence the `Yes recall` is 0.8).\n",
    "\n",
    "\n",
    "On the other hand second one is really balanced; almost the same amount of FN i FP. Only worryinh thing here is that we have a lot more of false negatives (better overall accuracy, but `Yes recall` is worse compared to the first model).\n",
    "\n",
    "But our tasks suggest that we should stick to having more balanced model, so we will stick with the second option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../artifacts/churn_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(svm_classifier_smote, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../artifacts/churn_model_features.pkl', 'wb') as model_file:\n",
    "    feature_names = list(svm_classifier_smote.feature_names_in_)\n",
    "    pickle.dump(feature_names, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cakeENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
